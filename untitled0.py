# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B1h8TD7-nkt1ve6xgPG2FEgdEP_ol-nx
"""

import pandas as pd

# Load the dataset directly from the URL
url = 'https://raw.githubusercontent.com/lakshyaRW/randomwalk-ds-assessment-level2/refs/heads/main/dataset.csv'
dataset = pd.read_csv(url)

# Inspect the dataset
print("Dataset Overview:\n", dataset.head())
print("Data Summary:\n", dataset.info())

#Q1
# Check for missing data in each column
print("Missing data:\n", dataset.isnull().sum())

# Drop rows with missing values
dataset_cleaned = dataset.dropna()

# Verify data types
print("Data types:\n", dataset.dtypes)

# Check for missing data after cleaning
print("After cleaning, missing data:\n", dataset_cleaned.isnull().sum())

#Q2
# Calculate the average of the 'body_mass_g' column
average_mass = dataset_cleaned['body_mass_g'].mean()
print("Average body_mass_g:", average_mass)

#Q3
# Calculate skewness and kurtosis for bill_length_mm and bill_depth_mm for each species
species_groups = dataset_cleaned.groupby('species')

for species, group in species_groups:
    skewness_bill_length = group['bill_length_mm'].skew()
    kurtosis_bill_length = group['bill_length_mm'].kurtosis()
    skewness_bill_depth = group['bill_depth_mm'].skew()
    kurtosis_bill_depth = group['bill_depth_mm'].kurtosis()

    print(f"{species} - Bill Length: Skewness={skewness_bill_length}, Kurtosis={kurtosis_bill_length}")
    print(f"{species} - Bill Depth: Skewness={skewness_bill_depth}, Kurtosis={kurtosis_bill_depth}")

#Q4
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Calculate Z-scores for numeric columns
z_scores = np.abs(stats.zscore(dataset_cleaned.select_dtypes(include=[np.number])))

# Visualize outliers using boxplots
dataset_cleaned.select_dtypes(include=[np.number]).boxplot(figsize=(10,6))
plt.title("Boxplots for Numerical Features (Outliers Detection)")
plt.show()

# Outliers are where Z-scores exceed 3
outliers = np.where(z_scores > 3)
print("Outliers found at positions:\n", outliers)

#Q5
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Convert species to numeric labels for plotting
label_encoder = LabelEncoder()
species_numeric = label_encoder.fit_transform(dataset_cleaned['species'])

# Perform PCA
pca = PCA(n_components=2)
numeric_data = dataset_cleaned.select_dtypes(include=[float, int])
pca_result = pca.fit_transform(numeric_data)

# Plot the PCA result, using the species label for coloring
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=species_numeric, cmap='viridis')
plt.title('PCA on Dataset')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.colorbar(label='Species')
plt.show()

# Print explained variance ratio
print(f"Explained variance by PCA components: {pca.explained_variance_ratio_}")

#Q6
import seaborn as sns

# Scatterplot
sns.scatterplot(data=dataset_cleaned, x='bill_length_mm', y='bill_depth_mm', hue='species')
plt.title('Scatterplot of Bill Length vs Bill Depth')
plt.show()

# Histogram
dataset_cleaned[['bill_length_mm', 'bill_depth_mm']].hist(bins=15, figsize=(10, 6))
plt.suptitle('Histograms of Bill Length and Bill Depth')
plt.show()

# Pairplot
sns.pairplot(dataset_cleaned[['bill_length_mm', 'bill_depth_mm', 'species']], hue='species')
plt.show()

# KDE Plot
sns.kdeplot(data=dataset_cleaned, x='bill_length_mm', y='bill_depth_mm', hue='species', fill=True)
plt.show()

# Boxplot
sns.boxplot(x='species', y='bill_length_mm', data=dataset_cleaned)
plt.show()

# Violin Plot
sns.violinplot(x='species', y='bill_depth_mm', data=dataset_cleaned)
plt.show()

# Jointplot
sns.jointplot(data=dataset_cleaned, x='bill_length_mm', y='bill_depth_mm', kind="hex")
plt.show()

#Q7
# Group by species and island, then find max 'flipper_length_mm'
max_flipper = dataset_cleaned.groupby(['species', 'island'])['flipper_length_mm'].max()

print("Maximum flipper_length_mm for each species and island:\n", max_flipper)

#Q8
from scipy.stats import zscore

# Apply z-score normalization to numeric columns
dataset_normalized = dataset_cleaned.copy()
dataset_normalized[dataset_cleaned.select_dtypes(include=[np.number]).columns] = dataset_cleaned.select_dtypes(include=[np.number]).apply(zscore)

# Check normalized dataset
print(dataset_normalized.head())